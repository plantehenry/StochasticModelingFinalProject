{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODuWPxobreviS72Zv3bfQf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Simple CNN Neural Network talking in a sequence of data (could have been an RNN, but had already tried that and it did not train well) to predict the future asset price"],"metadata":{"id":"oB38XL1EYSyy"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmBwBnDTZwcO","executionInfo":{"status":"ok","timestamp":1682208118754,"user_tz":240,"elapsed":910,"user":{"displayName":"Henry Plante","userId":"07474535296892436715"}},"outputId":"8f438e76-db53-412a-bc7f-8421e5da9dcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDGxKV5BaW9U","executionInfo":{"status":"ok","timestamp":1682208122854,"user_tz":240,"elapsed":4107,"user":{"displayName":"Henry Plante","userId":"07474535296892436715"}},"outputId":"370e47c2-ded1-4802-9342-5b5d62dee370"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EOzeh_CYXc1D","executionInfo":{"status":"error","timestamp":1682208544403,"user_tz":240,"elapsed":163,"user":{"displayName":"Henry Plante","userId":"07474535296892436715"}},"outputId":"d193f8f7-47f7-43b2-a3d4-03eec67af5c0"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-45419f13c1b8>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}: train loss = {train_loss:.6f}, val loss = {val_loss:.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-45419f13c1b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-45419f13c1b8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"]}],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","\n","class StockDataset(Dataset):\n","    def __init__(self, stocks_path, bonds_path, real_estate_path):\n","        stocks = pd.read_csv(stocks_path).values\n","        bonds = pd.read_csv(bonds_path).values\n","        real_estate = pd.read_csv(real_estate_path).values\n","        self.features = torch.stack((torch.from_numpy(stocks), torch.from_numpy(bonds), torch.from_numpy(real_estate)), dim=1)\n","        self.targets = torch.from_numpy(stocks[20:] / stocks[:-20] - 1).float() # percent price change for stocks\n","\n","    def __len__(self):\n","        return len(self.targets)\n","\n","    def __getitem__(self, idx):\n","        return self.features[idx:idx+20], self.targets[idx]\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv1d(3, 16, kernel_size=3, padding=1)\n","        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n","        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n","        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.fc1 = nn.Linear(64 * 2, 32)\n","        self.fc2 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x = x.squeeze(3)\n","        x = x.transpose(1,2)\n","        x = x.double()\n","        x = self.pool1(torch.relu(self.conv1(x)))\n","        x = self.pool2(torch.relu(self.conv2(x)))\n","        x = self.pool3(torch.relu(self.conv3(x)))\n","        x = x.view(-1, 64 * 2)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x.squeeze()\n","\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0\n","    for inputs, targets in dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","    return running_loss / len(dataloader.dataset)\n","\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            running_loss += loss.item() * inputs.size(0)\n","    return running_loss / len(dataloader.dataset)\n","\n","if __name__ == '__main__':\n","    stocks_path = \"/content/drive/My Drive/stochastic_stocks.csv\"\n","    bonds_path = \"/content/drive/My Drive/stochastic_bond.csv\"\n","    real_estate_path = \"/content/drive/My Drive/stochastic_re.csv\"\n","    dataset = StockDataset(stocks_path, bonds_path, real_estate_path)\n","    train_size = int(0.9 * len(dataset))\n","    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n","    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(val_dataset, batch_size=32)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = CNN().to(device)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    best_val_loss = float('inf')\n","    for epoch in range(50):\n","      train_loss = train(model, train_dataloader, criterion, optimizer, device)\n","      val_loss = evaluate(model, val_dataloader, criterion, device)\n","      print(f'Epoch {epoch+1}: train loss = {train_loss:.6f}, val loss = {val_loss:.6f}')\n","      if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import pandas as pd\n","\n","# Define the CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=3, out_channels=6, kernel_size=3)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv1d(in_channels=6, out_channels=16, kernel_size=3)\n","        self.fc1 = nn.Linear(in_features=48, out_features=120)\n","        self.fc2 = nn.Linear(in_features=120, out_features=84)\n","        self.fc3 = nn.Linear(in_features=84, out_features=1)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.flatten(1)\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Define a custom dataset\n","class StocksDataset(Dataset):\n","    def __init__(self, stocks_file, bonds_file, real_estate_file):\n","        self.stocks_data = pd.read_csv(stocks_file, header=None)\n","        self.bonds_data = pd.read_csv(bonds_file, header=None)\n","        self.real_estate_data = pd.read_csv(real_estate_file, header=None)\n","\n","    def __len__(self):\n","        return len(self.stocks_data) - 30\n","\n","    def __getitem__(self, index):\n","        stocks_seq = self.stocks_data.iloc[index :index + 20].values\n","        bonds_seq = self.bonds_data.iloc[index :index +20].values\n","        real_estate_seq = self.real_estate_data.iloc[index :index + 20].values\n","        try:\n","          label = (self.stocks_data.iloc[index + 20].values - self.stocks_data.iloc[index + 30].values) / self.stocks_data.iloc[index + 20].values\n","        except:\n","          print(len(self.stocks_data))\n","          print(index)\n","        # Convert the sequences to float tensors\n","        stocks_seq = torch.tensor(stocks_seq, dtype=torch.float32)\n","        bonds_seq = torch.tensor(bonds_seq, dtype=torch.float32)\n","        real_estate_seq = torch.tensor(real_estate_seq, dtype=torch.float32)\n","\n","        # Stack the sequences along the feature dimension\n","        stocks_seq = torch.tensor(stocks_seq, dtype=torch.float32)\n","        bonds_seq = torch.tensor(bonds_seq, dtype=torch.float32)\n","        real_estate_seq = torch.tensor(real_estate_seq, dtype=torch.float32)\n","        x = torch.stack([stocks_seq, bonds_seq, real_estate_seq], dim=0)\n","        x = x.squeeze(2)\n","        x = x.float()\n","        return x, label\n","\n","# Initialize the dataset and data loader\n","stocks_file = \"/content/drive/My Drive/stochastic_stocks.csv\"\n","bonds_file = \"/content/drive/My Drive/stochastic_bond.csv\"\n","real_estate_file = \"/content/drive/My Drive/stochastic_re.csv\"\n","dataset = StocksDataset(stocks_file, bonds_file, real_estate_file)\n","data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","# Initialize the model, loss function, and optimizer\n","model = CNN()\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, (inputs, labels) in enumerate(data_loader):\n","        optimizer.zero_grad()\n","        inputs = inputs.float()\n","        labels = labels.float()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        running_loss += loss.item()\n","    if i % 10 == 1:\n","        print(f\"Epoch {epoch+1}, batch {i+1}: Loss = {running_loss/10}\")\n","        running_loss = 0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUeTKiaXaHjo","executionInfo":{"status":"ok","timestamp":1682212104823,"user_tz":240,"elapsed":8835,"user":{"displayName":"Henry Plante","userId":"07474535296892436715"}},"outputId":"ac48bc89-2c9e-49a5-938d-7144893731ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-53-054f0bc6f06a>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  stocks_seq = torch.tensor(stocks_seq, dtype=torch.float32)\n","<ipython-input-53-054f0bc6f06a>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  bonds_seq = torch.tensor(bonds_seq, dtype=torch.float32)\n","<ipython-input-53-054f0bc6f06a>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  real_estate_seq = torch.tensor(real_estate_seq, dtype=torch.float32)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, batch 72: Loss = 54.20074441432953\n","Epoch 2, batch 72: Loss = 54.20074441432953\n","Epoch 3, batch 72: Loss = 54.20074441432953\n","Epoch 4, batch 72: Loss = 54.20074441432953\n","Epoch 5, batch 72: Loss = 54.20074441432953\n","Epoch 6, batch 72: Loss = 54.20074441432953\n","Epoch 7, batch 72: Loss = 54.20074441432953\n","Epoch 8, batch 72: Loss = 54.20074441432953\n","Epoch 9, batch 72: Loss = 54.20074441432953\n","Epoch 10, batch 72: Loss = 54.20074441432953\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KrMTDJEWdMlp"},"execution_count":null,"outputs":[]}]}